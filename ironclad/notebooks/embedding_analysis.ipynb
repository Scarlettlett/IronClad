{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up directory and sample path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for gallery images\n",
    "gallery_index_path = \"..\\\\storage\\\\multi_image_gallery\"\n",
    "\n",
    "# Define path for sample test\n",
    "probe_folder_path = \"..\\\\simclr_resources\\\\probe\"\n",
    "sample_probe_name = \"Ian_Thorpe\\\\Ian_Thorpe_0002.jpg\"\n",
    "sample_probe_path = os.path.join(probe_folder_path, sample_probe_name)\n",
    "sample_probe = Image.open(sample_probe_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - VGGFace2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gsjsc\\anaconda3\\envs\\en605645\\Lib\\site-packages\\facenet_pytorch\\models\\inception_resnet_v1.py:329: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(cached_file)\n"
     ]
    }
   ],
   "source": [
    "# Initialized pipeline for pre-trained model VGGFace2\n",
    "pretained1 = 'vggface2'\n",
    "pipeline1 = Pipeline(pretained1, index_type='brute_force', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed and saved embeddings for the gallery images.\n"
     ]
    }
   ],
   "source": [
    "# Define path for faiss index and metadata saving folders\n",
    "faiss_index_path1 = os.path.join('..', 'storage', f'catalog_{pretained1}')\n",
    "metadata_path1 = os.path.join('..', 'storage', f'catalog_{pretained1}')\n",
    "\n",
    "# Precompute and save faiss index and metadata for the model\n",
    "pipeline1.precompute_and_save(gallery_index_path, faiss_index_path1, metadata_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index and metadata for the model\n",
    "faiss_index_path1_load = os.path.join(faiss_index_path1, 'faiss_index.bin')\n",
    "metadata_path1_load = os.path.join(metadata_path1, 'metadata.pkl')\n",
    "\n",
    "pipeline1.index.load(faiss_index_path1_load, metadata_path1_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under model vggface2, for probe Ian_Thorpe\\Ian_Thorpe_0002.jpg, The top 5 nearest neighbors are:\n",
      "\n",
      "Index: 872, Distance: 0.6415, Name: ['Ian_Thorpe'], Filename: ['Ian_Thorpe_0006.jpg']\n",
      "Index: 1732, Distance: 0.6756, Name: ['Oscar_De_La_Hoya'], Filename: ['Oscar_De_La_Hoya_0003.jpg']\n",
      "Index: 871, Distance: 0.7435, Name: ['Ian_Thorpe'], Filename: ['Ian_Thorpe_0005.jpg']\n",
      "Index: 1716, Distance: 0.7961, Name: ['Noah_Wyle'], Filename: ['Noah_Wyle_0001.jpg']\n",
      "Index: 1500, Distance: 0.8049, Name: ['Mark_Dacey'], Filename: ['Mark_Dacey_0001.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Test case for one sample probe\n",
    "print(f\"Under model {pretained1}, for probe {sample_probe_name}, The top 5 nearest neighbors are:\\n\")\n",
    "results1 = pipeline1.search_gallery(sample_probe, 5)\n",
    "for result in results1:\n",
    "    print(f\"Index: {result['index']}, Distance: {result['distance']:.4f}, Name: {result['name']}, Filename: {result['filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - casia-webface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized pipeline for pre-trained model casia-webface\n",
    "pretained2 = 'casia-webface'\n",
    "pipeline2 = Pipeline(pretained2, index_type='brute_force', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed and saved embeddings for the gallery images.\n"
     ]
    }
   ],
   "source": [
    "# Define path for gallery images, faiss index and metadata saving folders\n",
    "faiss_index_path2 = os.path.join('..', 'storage', f'catalog_{pretained2}')\n",
    "metadata_path2 = os.path.join('..', 'storage', f'catalog_{pretained2}')\n",
    "\n",
    "# Precompute and save faiss index and metadata for the model\n",
    "pipeline2.precompute_and_save(gallery_index_path, faiss_index_path2, metadata_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index and metadata for the model\n",
    "faiss_index_path2_load = os.path.join(faiss_index_path2, 'faiss_index.bin')\n",
    "metadata_path2_load = os.path.join(metadata_path2, 'metadata.pkl')\n",
    "\n",
    "pipeline2.index.load(faiss_index_path2_load, metadata_path2_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under model casia-webface, for probe Ian_Thorpe\\Ian_Thorpe_0002.jpg, The top 5 nearest neighbors are:\n",
      "\n",
      "Index: 88, Distance: 0.2395, Name: ['Alvaro_Uribe'], Filename: ['Alvaro_Uribe_0005.jpg']\n",
      "Index: 642, Distance: 0.2857, Name: ['Gary_Williams'], Filename: ['Gary_Williams_0001.jpg']\n",
      "Index: 1325, Distance: 0.2909, Name: ['Kim_Ryong-sung'], Filename: ['Kim_Ryong-sung_0001.jpg']\n",
      "Index: 1150, Distance: 0.2940, Name: ['John_McEnroe'], Filename: ['John_McEnroe_0001.jpg']\n",
      "Index: 1595, Distance: 0.2980, Name: ['Michael_Phelps'], Filename: ['Michael_Phelps_0003.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Check result for the test case\n",
    "print(f\"Under model {pretained2}, for probe {sample_probe_name}, The top 5 nearest neighbors are:\\n\")\n",
    "results2 = pipeline2.search_gallery(sample_probe, 5)\n",
    "for result in results2:\n",
    "    print(f\"Index: {result['index']}, Distance: {result['distance']:.4f}, Name: {result['name']}, Filename: {result['filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop over all probes and calculate mean reciprocal rank\n",
    "def calculate_mrr(probe_folder_path, pipeline, k=5):\n",
    "\n",
    "    reciprocal_rank = 0\n",
    "    total_probe = 0\n",
    "\n",
    "    for probe_name in os.listdir(probe_folder_path):\n",
    "        probe_person_folder = os.path.join(probe_folder_path, probe_name)\n",
    "\n",
    "        for probe_file_name in os.listdir(probe_person_folder):\n",
    "            if probe_file_name.endswith(('.jpg', '.png', '.jpeg')) and not probe_file_name.startswith('._'):\n",
    "                image_path = os.path.join(probe_person_folder, probe_file_name)\n",
    "                total_probe += 1\n",
    "\n",
    "                try:\n",
    "                    with Image.open(image_path) as img:\n",
    "\n",
    "                        # 1. Get the top neighbors for the probe\n",
    "                        results = pipeline.search_gallery(img, k)\n",
    "\n",
    "                        #2. Check if the probe name are in the returned relevant items\n",
    "                        names = [result['name'] for result in results]\n",
    "                        for i in range(k):\n",
    "                            if probe_name == names[i][0]:\n",
    "                                reciprocal_rank += 1/(i+1)\n",
    "                                break\n",
    "\n",
    "                except PIL.UnidentifiedImageError:\n",
    "                    print(f\"Skipping file {image_path}: UnidentifiedImageError\")\n",
    "    \n",
    "    mrr = reciprocal_rank/total_probe * 100\n",
    "    print(f\"Mean Recriprocal Rank: {mrr:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model vggface2:\n",
      "Mean Recriprocal Rank: 56.58%\n"
     ]
    }
   ],
   "source": [
    "probe_folder_path = \"..\\\\simclr_resources\\\\probe\"\n",
    "print(f\"For model {pretained1}:\")\n",
    "calculate_mrr(probe_folder_path, pipeline1, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model casia-webface:\n",
      "Mean Recriprocal Rank: 11.77%\n"
     ]
    }
   ],
   "source": [
    "print(f\"For model {pretained2}:\")\n",
    "calculate_mrr(probe_folder_path, pipeline2, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop over all probes and calculate precision@k\n",
    "def precision_k(probe_folder_path, pipeline, k=5):\n",
    "\n",
    "    total_precision = 0\n",
    "    total_probe = 0\n",
    "\n",
    "    for probe_name in os.listdir(probe_folder_path):\n",
    "        probe_person_folder = os.path.join(probe_folder_path, probe_name)\n",
    "\n",
    "        for probe_file_name in os.listdir(probe_person_folder):\n",
    "            if probe_file_name.endswith(('.jpg', '.png', '.jpeg')) and not probe_file_name.startswith('._'):\n",
    "                image_path = os.path.join(probe_person_folder, probe_file_name)\n",
    "                total_probe += 1\n",
    "\n",
    "                try:\n",
    "                    with Image.open(image_path) as img:\n",
    "\n",
    "                        # 1. Get the top neighbors for the probe\n",
    "                        results = pipeline.search_gallery(img, k)\n",
    "\n",
    "                        # 2. Check if the probe name are in the returned relevant items\n",
    "                        relevant = 0\n",
    "\n",
    "                        names = [result['name'] for result in results]\n",
    "                        for i in range(k):\n",
    "                            if probe_name == names[i][0]:\n",
    "                                relevant += 1\n",
    "                        \n",
    "                        # 3. Calculate precision\n",
    "                        precision = relevant/k\n",
    "                        total_precision += precision\n",
    "\n",
    "                except PIL.UnidentifiedImageError:\n",
    "                    print(f\"Skipping file {image_path}: UnidentifiedImageError\")\n",
    "    \n",
    "    mrr = total_precision/total_probe\n",
    "    print(f\"Precision@k when k = {k}: {mrr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model vggface2:\n",
      "Precision@k when k = 5: 0.21\n"
     ]
    }
   ],
   "source": [
    "print(f\"For model {pretained1}:\")\n",
    "precision_k(probe_folder_path, pipeline1, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model casia-webface:\n",
      "Precision@k when k = 5: 0.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"For model {pretained2}:\")\n",
    "precision_k(probe_folder_path, pipeline2, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the image horizontally\n",
    "def horizontal_flip(image):\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "# Apply a Gaussian blur to smooth the image\n",
    "def gaussian_blur(image, kernel_size=(5, 5), sigma=0):\n",
    "    return cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "\n",
    "# Resize the image to the specified size\n",
    "def resize(image, new_size):\n",
    "    return cv2.resize(image, new_size)\n",
    "\n",
    "# Crop the image to the specified size\n",
    "def random_crop(image, crop_size):\n",
    "    h, w = image.shape[:2]\n",
    "    crop_h, crop_w = crop_size\n",
    "    start_y = np.random.randint(0, h - crop_h + 1)\n",
    "    start_x = np.random.randint(0, w - crop_w + 1)\n",
    "    return image[start_y:start_y + crop_h, start_x:start_x + crop_w]\n",
    "\n",
    "# Rotate the image by a given angle\n",
    "def rotate(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "# Increase or decrease the brightness of the image\n",
    "def adjust_brightness(image, value=30):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v = cv2.add(v, value)\n",
    "    v = np.clip(v, 0, 255)\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    return cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise_transformations(image):\n",
    "    \"\"\"\n",
    "    Apply various noise transformations to an image and return a dictionary \n",
    "    containing the transformed images.\n",
    "    \"\"\"\n",
    "    # Define various severity levels for transformations\n",
    "    severity_levels = {\n",
    "        'blur': [(15, 15), (31, 31)],  # kernel sizes for Gaussian blur\n",
    "        'brightness': [60, -60],     # brightness increase and decrease\n",
    "        'rotate': [15, 45],     # degrees to rotate\n",
    "        'crop_size': [(70, 70), (100, 100)]  # cropping sizes\n",
    "    }\n",
    "    \n",
    "    # Store all transformed images in a dictionary\n",
    "    transformed_images = {\n",
    "        'original': image,\n",
    "        'horizontal_flip': horizontal_flip(image),\n",
    "        'gaussian_blur_light': gaussian_blur(image, severity_levels['blur'][0]),\n",
    "        'gaussian_blur_strong': gaussian_blur(image, severity_levels['blur'][1]),\n",
    "        'resize_small': resize(image, (128, 128)),\n",
    "        'resize_large': resize(image, (256, 256)),\n",
    "        'random_crop_small': random_crop(image, severity_levels['crop_size'][0]),\n",
    "        'random_crop_large': random_crop(image, severity_levels['crop_size'][1]),\n",
    "        'rotate_small': rotate(image, severity_levels['rotate'][0]),\n",
    "        'rotate_large': rotate(image, severity_levels['rotate'][1]),\n",
    "        'brightness_increase': adjust_brightness(image, severity_levels['brightness'][0]),\n",
    "        'brightness_decrease': adjust_brightness(image, severity_levels['brightness'][1])\n",
    "    }\n",
    "    \n",
    "    return transformed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformed_images_mrr(probe_folder_path, pipeline, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate the Mean Reciprocal Rank (MRR) performance impacts of various noise transformations \n",
    "    on probe images.\n",
    "    \"\"\"\n",
    "    total_mrr = {key: 0 for key in ['original', 'horizontal_flip', 'gaussian_blur_light', 'gaussian_blur_strong',\n",
    "                                    'resize_small', 'resize_large', 'random_crop_small', 'random_crop_large',\n",
    "                                    'rotate_small', 'rotate_large', 'brightness_increase', 'brightness_decrease']}\n",
    "    \n",
    "    total_probes = 0\n",
    "\n",
    "    for probe_name in os.listdir(probe_folder_path):\n",
    "        probe_person_folder = os.path.join(probe_folder_path, probe_name)\n",
    "\n",
    "        for probe_file_name in os.listdir(probe_person_folder):\n",
    "            if probe_file_name.endswith(('.jpg', '.png', '.jpeg')) and not probe_file_name.startswith('._'):\n",
    "                image_path = os.path.join(probe_person_folder, probe_file_name)\n",
    "                total_probes += 1\n",
    "\n",
    "                try:\n",
    "                    # Open the image\n",
    "                    probe_image = Image.open(image_path)\n",
    "                    probe_image_cv2 = np.array(probe_image)\n",
    "\n",
    "                    # Apply noise transformations\n",
    "                    transformed_images = apply_noise_transformations(probe_image_cv2)\n",
    "\n",
    "                    # Evaluate for each transformation\n",
    "                    for transform_name, transformed_image in transformed_images.items():\n",
    "                        transformed_image_pil = Image.fromarray(transformed_image)\n",
    "                        \n",
    "                        # Get the top neighbors for the transformed probe image\n",
    "                        results = pipeline.search_gallery(transformed_image_pil, k)\n",
    "\n",
    "                        # Calculate Reciprocal Rank for the transformation\n",
    "                        names = [result['name'] for result in results]\n",
    "                        reciprocal_rank = 0\n",
    "\n",
    "                        for i in range(k):\n",
    "                            if probe_name == names[i][0]:\n",
    "                                reciprocal_rank = 1 / (i + 1)\n",
    "                                break \n",
    "                        \n",
    "                        # Add reciprocal rank to total\n",
    "                        total_mrr[transform_name] += reciprocal_rank\n",
    "\n",
    "                except PIL.UnidentifiedImageError:\n",
    "                    print(f\"Skipping file {image_path}: UnidentifiedImageError\")\n",
    "\n",
    "    # Calculate the average MRR for each transformation\n",
    "    for transform_name in total_mrr:\n",
    "        avg_mrr = total_mrr[transform_name] / total_probes\n",
    "        print(f\"Transformation: {transform_name} | Mean Reciprocal Rank (MRR): {avg_mrr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original | Mean Reciprocal Rank (MRR): 0.57\n",
      "Transformation: horizontal_flip | Mean Reciprocal Rank (MRR): 0.56\n",
      "Transformation: gaussian_blur_light | Mean Reciprocal Rank (MRR): 0.44\n",
      "Transformation: gaussian_blur_strong | Mean Reciprocal Rank (MRR): 0.09\n",
      "Transformation: resize_small | Mean Reciprocal Rank (MRR): 0.57\n",
      "Transformation: resize_large | Mean Reciprocal Rank (MRR): 0.57\n",
      "Transformation: random_crop_small | Mean Reciprocal Rank (MRR): 0.02\n",
      "Transformation: random_crop_large | Mean Reciprocal Rank (MRR): 0.12\n",
      "Transformation: rotate_small | Mean Reciprocal Rank (MRR): 0.48\n",
      "Transformation: rotate_large | Mean Reciprocal Rank (MRR): 0.04\n",
      "Transformation: brightness_increase | Mean Reciprocal Rank (MRR): 0.28\n",
      "Transformation: brightness_decrease | Mean Reciprocal Rank (MRR): 0.20\n"
     ]
    }
   ],
   "source": [
    "evaluate_transformed_images_mrr(probe_folder_path, pipeline1, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Effects:**\n",
    "The system shows minimal sensitivity to horizontal flips and resizing, with slight degradation under small rotations and light blur. However, strong blur, large rotations, and significant brightness changes cause notable performance drops, especially in random crops, which severely impair accuracy.\n",
    "\n",
    "**Design Thoughts:**\n",
    "To improve robustness, the system should incorporate image preprocessing steps like face detection, alignment, and brightness normalization. Training with augmented data that includes small rotations, light blurs, and brightness variations can make the model more resilient. For extreme cases (e.g., strong blur or large rotation), the system could trigger a re-capture mechanism to ensure image quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
